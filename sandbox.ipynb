{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd0007e-5619-4437-8582-945e85511c70",
   "metadata": {},
   "source": [
    "# Color Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70380ce-d5bb-4856-814e-bcf396e78ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze import analyze_color_histogram\n",
    "from scg_detection_tools.models import YOLO_NAS, YOLOv8\n",
    "from scg_detection_tools.detect import Detector\n",
    "from scg_detection_tools.utils.file_handling import read_yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import cv2\n",
    "\n",
    "cfg = read_yaml(\"analyze_config.yaml\")\n",
    "#model = YOLOv8(yolov8_ckpt_path=cfg[\"yolov8_model_path\"])\n",
    "model = YOLO_NAS(model_arch=cfg[\"yolonas_arch\"], \n",
    "                 checkpoint_path=cfg[\"yolonas_model_path\"], \n",
    "                 classes=cfg[\"data_classes\"])\n",
    "det_params = cfg[\"detect_parameters\"]\n",
    "det_params[\"embed_slice_callback\"] = None\n",
    "det = Detector(detection_model=model, detection_params=det_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccd930a-3420-4bd3-afa2-2dbf70c74a0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scg_detection_tools.utils.file_handling import get_all_files_from_paths\n",
    "\n",
    "IMG_DIR = \"/home/julio/Dev/SCG_IFSC/save/light_group_annotations/images\"\n",
    "LBL_DIR = \"/home/julio/Dev/SCG_IFSC/save/light_group_annotations/labels\"\n",
    "\n",
    "#IMG_DIR = \"/home/julio/Dev/SCG_IFSC/save/hemacias/images\"\n",
    "\n",
    "imgs = get_all_files_from_paths(IMG_DIR)\n",
    "\n",
    "img_hists = analyze_color_histogram(model=model, \n",
    "                                    detector=det, \n",
    "                                    imgs=imgs, \n",
    "                                    raw=False, \n",
    "                                    on_detection_boxes=False,\n",
    "                                    seg_annotations=LBL_DIR, \n",
    "                                    cspaces=[\"RGB\", \"HSV\", \"GRAY\"], \n",
    "                                    show=True, save_plots=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524f61d7-497f-4a46-9982-1e269442e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot single channel images\n",
    "\n",
    "import os\n",
    "\n",
    "save = False\n",
    "for img in imgs:\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12,8))\n",
    "    \n",
    "    rgb = cv2.imread(img)\n",
    "    rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
    "    hsv = cv2.cvtColor(rgb.copy(), cv2.COLOR_RGB2HSV)\n",
    "    LABELS = [\"RGB\", \"HSV\"]\n",
    "    for ci, cp in enumerate([rgb, hsv]):\n",
    "        for i in range(3):\n",
    "            ch = cp.copy()\n",
    "            for j in range(3):\n",
    "                if i != j:\n",
    "                    ch[:,:,j] = 0\n",
    "            axs[ci][i].axis(\"off\")\n",
    "            axs[ci][i].imshow(ch)\n",
    "            axs[ci][i].set_title(LABELS[ci][i])\n",
    "    if save:\n",
    "        fig.savefig(f\"exp_analysis/singlechannel_{os.path.basename(img)}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2bb6cf-1256-4cd2-b132-47aee92ce337",
   "metadata": {},
   "outputs": [],
   "source": [
    "cspaceAnalysis = {\"RGB\": [], \"HSV\": [], \"GRAY\": [], \"ALL\": []}\n",
    "nclass = {0: \"light\", 1: \"medium\", 2: \"dark\", 3: \"dead\"}\n",
    "intensities = np.arange(256)\n",
    "\n",
    "for img in img_hists:\n",
    "    img_hist = img_hists[img]\n",
    "    for cspace in [\"RGB\", \"HSV\", \"GRAY\"]:\n",
    "        for mask_hist in img_hist[cspace][\"masks\"]:\n",
    "            hist = mask_hist[\"hist\"]\n",
    "            mask_class = nclass[mask_hist[\"class\"]]\n",
    "\n",
    "            ch_stats = []\n",
    "            for ch_hist in hist:\n",
    "                ch_mean = np.sum(intensities * ch_hist) / np.sum(ch_hist)\n",
    "                ch_std = np.sqrt(np.sum((intensities - ch_mean) ** 2 * ch_hist) / np.sum(ch_hist))\n",
    "                ch_stats.append([ch_mean, ch_std])\n",
    "            \n",
    "            ch_stats = np.array(ch_stats).T.ravel().tolist()\n",
    "            ch_stats.append(mask_class)\n",
    "            cspaceAnalysis[cspace].append(ch_stats)\n",
    "\n",
    "\n",
    "num_masks = len(cspaceAnalysis[\"RGB\"])\n",
    "all_mean = []\n",
    "all_std = []\n",
    "all_class = [data[-1] for data in cspaceAnalysis[\"RGB\"]]\n",
    "\n",
    "for maskidx in range(num_masks):\n",
    "    all_mean.append([])\n",
    "    all_std.append([])\n",
    "    for cspace in [\"RGB\", \"HSV\", \"GRAY\"]:\n",
    "        data = cspaceAnalysis[cspace][maskidx]\n",
    "        if cspace == \"GRAY\":\n",
    "            ch_mean = data[0]\n",
    "            ch_std = data[1]\n",
    "            all_mean[-1].append(ch_mean)\n",
    "            all_std[-1].append(ch_std)\n",
    "        else:\n",
    "            ch_mean = data[:3]\n",
    "            ch_std = data[3:-1]\n",
    "            all_mean[-1].extend(ch_mean)\n",
    "            all_std[-1].extend(ch_std)\n",
    "for i in range(num_masks):\n",
    "    cspaceAnalysis[\"ALL\"].append([])\n",
    "    \n",
    "    cspaceAnalysis[\"ALL\"][i].extend(all_mean[i])\n",
    "    cspaceAnalysis[\"ALL\"][i].extend(all_std[i])\n",
    "    cspaceAnalysis[\"ALL\"][i].append(all_class[i])\n",
    "\n",
    "rgbdf = pd.DataFrame(cspaceAnalysis[\"RGB\"], columns=[\n",
    "    \"R Mean\", \"G Mean\", \"B Mean\", \"R std\", \"G std\", \"B std\", \"Class\"\n",
    "])\n",
    "hsvdf = pd.DataFrame(cspaceAnalysis[\"HSV\"], columns=[\n",
    "    \"H Mean\", \"S Mean\", \"V Mean\", \"H std\", \"S std\", \"V std\", \"Class\"\n",
    "])\n",
    "graydf = pd.DataFrame(cspaceAnalysis[\"GRAY\"], columns=[\n",
    "    \"Gray mean\", \"Gray std\", \"Class\"\n",
    "])\n",
    "\n",
    "alldf = pd.DataFrame(cspaceAnalysis[\"ALL\"], columns=[\n",
    "    \"R Mean\", \"G Mean\", \"B Mean\", \"H Mean\", \"S Mean\", \"V Mean\", \"Gray mean\", \"R std\", \"G std\", \"B std\", \"H std\", \"S std\", \"V std\", \"Gray std\", \"Class\"\n",
    "])\n",
    "\n",
    "class_c_map = {\n",
    "    \"light\": \"blue\", \n",
    "    \"medium\": \"green\", \n",
    "    \"dark\": \"red\", \n",
    "    \"dead\": \"black\"\n",
    "}\n",
    "\n",
    "class_color = lambda df: df[\"Class\"].map(class_c_map)\n",
    "\n",
    "scatter_matrix(rgbdf.iloc[:,:-1], figsize=(12,12), diagonal=\"kde\", color=class_color(rgbdf))\n",
    "scatter_matrix(hsvdf.iloc[:,:-1], figsize=(12,12), diagonal=\"kde\", color=class_color(hsvdf))\n",
    "scatter_matrix(graydf.iloc[:,:-1], figsize=(12,12), diagonal=\"kde\", color=class_color(graydf))\n",
    "scatter_matrix(alldf.iloc[:,:-1], figsize=(20,20), diagonal=\"kde\", color=class_color(alldf))\n",
    "\n",
    "print(rgbdf.corr(numeric_only=True))\n",
    "print(hsvdf.corr(numeric_only=True))\n",
    "print(graydf.corr(numeric_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767042a3-1664-48f2-b52c-df81867a4bf0",
   "metadata": {},
   "source": [
    "# Clustering and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "998ca563-9aad-49f7-bd4a-a7078d69845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "KMeans:\n",
    "\n",
    "Use k-means to find clusters based on leaf masks extracted with yolo and sam2\n",
    "- (for now) use the features from above (RGB, HSV, Gray means and std), pass them to PSA\n",
    "- to get it to 2 and 3 dimensions (compare them) then use them to train KMeans\n",
    "- and also plot inertia x n_clusters to check for optimal values\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# alldf is a dataset of 14 features (RGB,HSV,Gray)(Mean,STD) not including class\n",
    "# it will only be used to color markers in plot\n",
    "#print(alldf.head())\n",
    "#print(alldf.iloc[:,:-1].values)\n",
    "X = alldf.iloc[:,:-1].values\n",
    "\n",
    "# Use PCA to reduce to 2d\n",
    "reduced = PCA(n_components=2).fit_transform(X)\n",
    "\n",
    "# Feature scaling to normalize values and have a stdv of 1 and mean of 0\n",
    "scaler = StandardScaler().set_output(transform=\"pandas\")\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "scaled_PCA = PCA(n_components=2).fit_transform(scaled_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c208b849-a7be-42d4-8476-d69fa5903fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze inertia to choose best numbmer for clusters\n",
    "inertia = []\n",
    "MAX_CLUSTERS = 15\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12,8), layout=\"tight\")\n",
    "for i, (name, data) in enumerate([(\"PCA reduced\",reduced), (\"Scale + PCA reduced\",scaled_PCA)]):\n",
    "    inertia = []\n",
    "    for n in range(1, MAX_CLUSTERS):\n",
    "        kmeans = KMeans(n_clusters=n, init=\"k-means++\", n_init=10, max_iter=300,\n",
    "                        tol=0.0001, random_state=0, algorithm=\"lloyd\")\n",
    "        kmeans.fit(data)\n",
    "        inertia.append(kmeans.inertia_)\n",
    "    axs[i].plot(np.arange(1, MAX_CLUSTERS), inertia, marker='o')\n",
    "    axs[i].set(xlabel=\"# Clusters\", ylabel=\"Inertia\", title=name)\n",
    "    del inertia\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a886ba00-3dae-4b47-9dda-8228a1326958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_test(n_clusters, data, name):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, init=\"k-means++\", max_iter=300,\n",
    "                   tol=0.001, random_state=0, algorithm=\"lloyd\")\n",
    "\n",
    "    kmeans.fit(data)\n",
    "\n",
    "    ## visualization\n",
    "    step = 0.02\n",
    "    x_min, x_max = data[:,0].min() - 1, data[:,0].max() + 1\n",
    "    y_min, y_max = data[:,1].min() - 1, data[:,1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, step), np.arange(y_min, y_max, step))\n",
    "\n",
    "    Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(Z, interpolation=\"nearest\", extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "          cmap=plt.cm.Paired, aspect=\"auto\", origin=\"lower\")\n",
    "\n",
    "    for c in class_c_map:\n",
    "        c_data = reduced[alldf[\"Class\"] == c,:]\n",
    "        ax.scatter(c_data[:,0], c_data[:,1], color=class_c_map[c], alpha=0.8)\n",
    "    \n",
    "    #ax.plot(reduced[:,0], reduced[:,1], )\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    ax.scatter(centroids[:,0], centroids[:,1], marker=\"x\", s=169, color=\"w\", zorder=10, linewidth=3)\n",
    "    ax.set(title=f\"K-Means clustering on leaves masks using {name}\",\n",
    "           xlim=(x_min, x_max),\n",
    "           ylim=(y_min, y_max))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363b99d3-d2ba-414e-aeb1-93245849b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_test(n_clusters=4, data=reduced, name=\"PCA reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146f04dd-4d61-4b93-bb48-efd998c7b3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing N clusters because of above\n",
    "N_CLUSTERS = 4\n",
    "kmeans = KMeans(n_clusters=N_CLUSTERS, init=\"k-means++\", max_iter=300,\n",
    "                tol=0.0001, random_state=0, algorithm=\"lloyd\")\n",
    "kmeans.fit(reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84f0a6e-978b-4148-9783-99bcd25d33ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters\n",
    "h = 0.02\n",
    "\n",
    "x_min, x_max = reduced[:,0].min() - 1, reduced[:,0].max() + 1\n",
    "y_min, y_max = reduced[:,1].min() - 1, reduced[:,1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea22b9be-43e6-468e-816b-dcff18238714",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(Z, interpolation=\"nearest\", extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "          cmap=plt.cm.Paired, aspect=\"auto\", origin=\"lower\")\n",
    "\n",
    "for c in class_c_map:\n",
    "    c_data = reduced[alldf[\"Class\"] == c,:]\n",
    "    ax.scatter(c_data[:,0], c_data[:,1], color=class_c_map[c], alpha=0.8)\n",
    "\n",
    "#ax.plot(reduced[:,0], reduced[:,1], )\n",
    "centroids = kmeans.cluster_centers_\n",
    "ax.scatter(centroids[:,0], centroids[:,1], marker=\"x\", s=169, color=\"w\", zorder=10, linewidth=3)\n",
    "ax.set(title=\"K-Means clustering on leaves masks\",\n",
    "       xlim=(x_min, x_max),\n",
    "       ylim=(y_min, y_max))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2533cb3f-2082-4157-bcb4-a231c83c9958",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "K Nearest Neighbors:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478f269d-4b5a-4ee7-a059-1e375344c8df",
   "metadata": {},
   "source": [
    "# Pixel density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fa0ce2-ddfd-49c4-81cd-5e3d6cd0d682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze import analyze_pixel_density\n",
    "from scg_detection_tools.utils.file_handling import get_all_files_from_paths\n",
    "from pathlib import Path\n",
    "\n",
    "IMG_DIR = \"/home/julio/Dev/SCG_IFSC/scg-leaf-count/imgs/analysis\"\n",
    "LBL_DIR = \"/home/julio/Dev/SCG_IFSC/save/first_analysis_detections/out_cache/\"\n",
    "\n",
    "imgs = get_all_files_from_paths(IMG_DIR)\n",
    "\n",
    "def sort_stem(item):\n",
    "    s = Path(item).stem\n",
    "    try:\n",
    "        val = int(s)\n",
    "        return val\n",
    "    except:\n",
    "        return s\n",
    "\n",
    "imgs = sorted(imgs, key=sort_stem)\n",
    "print(imgs)\n",
    "\n",
    "densities = analyze_pixel_density(model=model, \n",
    "                                  detector=det, \n",
    "                                  imgs=imgs, \n",
    "                                  sam2_ckpt_path=cfg[\"sam2_ckpt_path\"],\n",
    "                                  sam2_cfg=cfg[\"sam2_cfg\"],\n",
    "                                  boxes=True,\n",
    "                                  segments=False,\n",
    "                                  slice_detection=True,\n",
    "                                  on_slice=False,\n",
    "                                  seg_annotations=None,\n",
    "                                  cached_detections=None,\n",
    "                                  show=True,\n",
    "                                  save=True)\n",
    "print(densities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
