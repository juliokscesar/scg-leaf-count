{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd0007e-5619-4437-8582-945e85511c70",
   "metadata": {},
   "source": [
    "# Color Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70380ce-d5bb-4856-814e-bcf396e78ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze import analyze_color_histogram\n",
    "from scg_detection_tools.models import YOLO_NAS, YOLOv8\n",
    "from scg_detection_tools.detect import Detector\n",
    "from scg_detection_tools.utils.file_handling import read_yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import cv2\n",
    "\n",
    "cfg = read_yaml(\"analyze_config.yaml\")\n",
    "model = YOLOv8(yolov8_ckpt_path=cfg[\"yolov8_model_path\"])\n",
    "#model = YOLO_NAS(model_arch=cfg[\"yolonas_arch\"], \n",
    "#                checkpoint_path=cfg[\"yolonas_model_path\"], \n",
    "#                classes=cfg[\"data_classes\"])\n",
    "det_params = cfg[\"detect_parameters\"]\n",
    "det_params[\"embed_slice_callback\"] = None\n",
    "det = Detector(detection_model=model, detection_params=det_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccd930a-3420-4bd3-afa2-2dbf70c74a0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scg_detection_tools.utils.file_handling import get_all_files_from_paths\n",
    "\n",
    "IMG_DIR = \"/home/juliocesar/leaf-detection/imgs/light_group/images\"\n",
    "LBL_DIR = \"/home/juliocesar/leaf-detection/imgs/light_group/labels\"\n",
    "\n",
    "#IMG_DIR = \"/home/julio/Dev/SCG_IFSC/save/hemacias/images\"\n",
    "\n",
    "imgs = get_all_files_from_paths(IMG_DIR)\n",
    "\n",
    "img_hists = analyze_color_histogram(model=model, \n",
    "                                    detector=det, \n",
    "                                    imgs=imgs, \n",
    "                                    raw=False, \n",
    "                                    on_detection_boxes=False,\n",
    "                                    seg_annotations=LBL_DIR, \n",
    "                                    cspaces=[\"RGB\", \"HSV\", \"GRAY\"], \n",
    "                                    show=True, save_plots=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524f61d7-497f-4a46-9982-1e269442e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot single channel images\n",
    "\n",
    "import os\n",
    "\n",
    "save = False\n",
    "for img in imgs:\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12,8))\n",
    "    \n",
    "    rgb = cv2.imread(img)\n",
    "    rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
    "    hsv = cv2.cvtColor(rgb.copy(), cv2.COLOR_RGB2HSV)\n",
    "    LABELS = [\"RGB\", \"HSV\"]\n",
    "    for ci, cp in enumerate([rgb, hsv]):\n",
    "        for i in range(3):\n",
    "            ch = cp.copy()\n",
    "            for j in range(3):\n",
    "                if i != j:\n",
    "                    ch[:,:,j] = 0\n",
    "            axs[ci][i].axis(\"off\")\n",
    "            axs[ci][i].imshow(ch)\n",
    "            axs[ci][i].set_title(LABELS[ci][i])\n",
    "    if save:\n",
    "        fig.savefig(f\"exp_analysis/singlechannel_{os.path.basename(img)}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2bb6cf-1256-4cd2-b132-47aee92ce337",
   "metadata": {},
   "outputs": [],
   "source": [
    "cspaceAnalysis = {\"RGB\": [], \"HSV\": [], \"GRAY\": [], \"ALL\": []}\n",
    "nclass = {0: \"light\", 1: \"medium\", 2: \"dark\", 3: \"dead\"}\n",
    "intensities = np.arange(256)\n",
    "for img in img_hists:\n",
    "    img_hist = img_hists[img]\n",
    "    for cspace in [\"RGB\", \"HSV\", \"GRAY\"]:\n",
    "        for mask_hist in img_hist[cspace][\"masks\"]:\n",
    "            hist = mask_hist[\"hist\"]\n",
    "            mask_class = nclass[mask_hist[\"class\"]]\n",
    "\n",
    "            ch_stats = []\n",
    "            for ch_hist in hist:\n",
    "                ch_mean = np.sum(intensities * ch_hist) / np.sum(ch_hist)\n",
    "                ch_std = np.sqrt(np.sum((intensities - ch_mean) ** 2 * ch_hist) / np.sum(ch_hist))\n",
    "                ch_stats.append([ch_mean, ch_std])\n",
    "            \n",
    "            ch_stats = np.array(ch_stats).T.ravel().tolist()\n",
    "            ch_stats.append(mask_class)\n",
    "            cspaceAnalysis[cspace].append(ch_stats)\n",
    "\n",
    "\n",
    "num_masks = len(cspaceAnalysis[\"RGB\"])\n",
    "all_mean = []\n",
    "all_std = []\n",
    "all_class = [data[-1] for data in cspaceAnalysis[\"RGB\"]]\n",
    "\n",
    "for maskidx in range(num_masks):\n",
    "    all_mean.append([])\n",
    "    all_std.append([])\n",
    "    for cspace in [\"RGB\", \"HSV\", \"GRAY\"]:\n",
    "        data = cspaceAnalysis[cspace][maskidx]\n",
    "        if cspace == \"GRAY\":\n",
    "            ch_mean = data[0]\n",
    "            ch_std = data[1]\n",
    "            all_mean[-1].append(ch_mean)\n",
    "            all_std[-1].append(ch_std)\n",
    "        else:\n",
    "            ch_mean = data[:3]\n",
    "            ch_std = data[3:-1]\n",
    "            all_mean[-1].extend(ch_mean)\n",
    "            all_std[-1].extend(ch_std)\n",
    "for i in range(num_masks):\n",
    "    cspaceAnalysis[\"ALL\"].append([])\n",
    "    \n",
    "    cspaceAnalysis[\"ALL\"][i].extend(all_mean[i])\n",
    "    cspaceAnalysis[\"ALL\"][i].extend(all_std[i])\n",
    "    cspaceAnalysis[\"ALL\"][i].append(all_class[i])\n",
    "\n",
    "rgbdf = pd.DataFrame(cspaceAnalysis[\"RGB\"], columns=[\n",
    "    \"R Mean\", \"G Mean\", \"B Mean\", \"R std\", \"G std\", \"B std\", \"Class\"\n",
    "])\n",
    "hsvdf = pd.DataFrame(cspaceAnalysis[\"HSV\"], columns=[\n",
    "    \"H Mean\", \"S Mean\", \"V Mean\", \"H std\", \"S std\", \"V std\", \"Class\"\n",
    "])\n",
    "graydf = pd.DataFrame(cspaceAnalysis[\"GRAY\"], columns=[\n",
    "    \"Gray mean\", \"Gray std\", \"Class\"\n",
    "])\n",
    "\n",
    "alldf = pd.DataFrame(cspaceAnalysis[\"ALL\"], columns=[\n",
    "    \"R Mean\", \"G Mean\", \"B Mean\", \"H Mean\", \"S Mean\", \"V Mean\", \"Gray mean\", \"R std\", \"G std\", \"B std\", \"H std\", \"S std\", \"V std\", \"Gray std\", \"Class\"\n",
    "])\n",
    "\n",
    "class_c_map = {\n",
    "    \"light\": \"blue\", \n",
    "    \"medium\": \"green\", \n",
    "    \"dark\": \"red\", \n",
    "    \"dead\": \"black\"\n",
    "}\n",
    "\n",
    "class_color = lambda df: df[\"Class\"].map(class_c_map)\n",
    "\n",
    "scatter_matrix(rgbdf.iloc[:,:-1], figsize=(12,12), diagonal=\"kde\", color=class_color(rgbdf))\n",
    "scatter_matrix(hsvdf.iloc[:,:-1], figsize=(12,12), diagonal=\"kde\", color=class_color(hsvdf))\n",
    "scatter_matrix(graydf.iloc[:,:-1], figsize=(12,12), diagonal=\"kde\", color=class_color(graydf))\n",
    "scatter_matrix(alldf.iloc[:,:-1], figsize=(20,20), diagonal=\"kde\", color=class_color(alldf))\n",
    "\n",
    "print(rgbdf.corr(numeric_only=True))\n",
    "print(hsvdf.corr(numeric_only=True))\n",
    "print(graydf.corr(numeric_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767042a3-1664-48f2-b52c-df81867a4bf0",
   "metadata": {},
   "source": [
    "# Clustering and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "998ca563-9aad-49f7-bd4a-a7078d69845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "KMeans:\n",
    "\n",
    "Use k-means to find clusters based on leaf masks extracted with yolo and sam2\n",
    "- (for now) use the features from above (RGB, HSV, Gray means and std), pass them to PSA\n",
    "- to get it to 2 and 3 dimensions (compare them) then use them to train KMeans\n",
    "- and also plot inertia x n_clusters to check for optimal values\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# alldf is a dataset of 14 features (RGB,HSV,Gray)(Mean,STD) not including class\n",
    "# it will only be used to color markers in plot\n",
    "#print(alldf.head())\n",
    "#print(alldf.iloc[:,:-1].values)\n",
    "X = alldf.iloc[:,:-1].values\n",
    "\n",
    "# Use PCA to reduce to 2d\n",
    "reduced = PCA(n_components=2).fit_transform(X)\n",
    "\n",
    "# Feature scaling to normalize values and have a stdv of 1 and mean of 0\n",
    "# so first scale then apply PCA\n",
    "scaler = StandardScaler().set_output(transform=\"pandas\")\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "scaled_PCA = PCA(n_components=2).fit_transform(scaled_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c208b849-a7be-42d4-8476-d69fa5903fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze inertia to choose best numbmer for clusters\n",
    "inertia = []\n",
    "MAX_CLUSTERS = 15\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12,8), layout=\"tight\")\n",
    "for i, (name, data) in enumerate([(\"PCA reduced\",reduced), (\"Scale + PCA reduced\",scaled_PCA)]):\n",
    "    inertia = []\n",
    "    for n in range(1, MAX_CLUSTERS):\n",
    "        kmeans = KMeans(n_clusters=n, init=\"k-means++\", n_init=10, max_iter=300,\n",
    "                        tol=0.0001, random_state=0, algorithm=\"lloyd\")\n",
    "        kmeans.fit(data)\n",
    "        inertia.append(kmeans.inertia_)\n",
    "    axs[i].plot(np.arange(1, MAX_CLUSTERS), inertia, marker='o')\n",
    "    axs[i].set(xlabel=\"# Clusters\", ylabel=\"Inertia\", title=name)\n",
    "    del inertia\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a886ba00-3dae-4b47-9dda-8228a1326958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_test(n_clusters, data, name):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, init=\"k-means++\", max_iter=300,\n",
    "                   tol=0.001, random_state=0, algorithm=\"lloyd\")\n",
    "\n",
    "    kmeans.fit(data)\n",
    "\n",
    "    ## visualization\n",
    "    step = 0.02\n",
    "    x_min, x_max = data[:,0].min() - 1, data[:,0].max() + 1\n",
    "    y_min, y_max = data[:,1].min() - 1, data[:,1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, step), np.arange(y_min, y_max, step))\n",
    "\n",
    "    Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(Z, interpolation=\"nearest\", extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "          cmap=plt.cm.Paired, aspect=\"auto\", origin=\"lower\")\n",
    "\n",
    "    for c in class_c_map:\n",
    "        c_data = data[alldf[\"Class\"] == c,:]\n",
    "        ax.scatter(c_data[:,0], c_data[:,1], color=class_c_map[c], alpha=0.8)\n",
    "    \n",
    "    #ax.plot(reduced[:,0], reduced[:,1], )\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    ax.scatter(centroids[:,0], centroids[:,1], marker=\"x\", s=169, color=\"w\", zorder=10, linewidth=3)\n",
    "    ax.set(title=f\"K-Means clustering on leaves masks using {name}\",\n",
    "           xlim=(x_min, x_max),\n",
    "           ylim=(y_min, y_max))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363b99d3-d2ba-414e-aeb1-93245849b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_test(n_clusters=4, data=reduced, name=\"PCA reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a38d6-1ac3-4a6e-8391-7afc6a1e9101",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_test(n_clusters=4, data=scaled_PCA, name=\"Scale + PCA reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac0b15e-d5ff-45f5-8c36-4c9f5c5c1417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing with sklearn pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "N_CLUSTERS = 4\n",
    "scaler = StandardScaler().set_output(transform=\"pandas\")\n",
    "pca = PCA(n_components=2)\n",
    "pipe = Pipeline(\n",
    "    steps=[(\"scaler\", scaler), (\"pca\", pca)]\n",
    ")\n",
    "transformed = pipe.fit_transform(X)\n",
    "kmeans_test(n_clusters=N_CLUSTERS, data=transformed, name=\"Pipeline: Scaler to PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2533cb3f-2082-4157-bcb4-a231c83c9958",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "K Nearest Neighbors:\n",
    "- To decide on the value of K, test for a range\n",
    "- Use a pipeline\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = alldf.iloc[:,:-1].values\n",
    "y = alldf.iloc[:,-1].values\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoded = encoder.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, encoded, stratify=encoded, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8f29b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()), (\"knn\", KNeighborsClassifier(n_neighbors=5)),\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f723832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"len X_test: {len(X_test)}\")\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "print(f\"predicted,real:\\n{[(p, r) for p,r in zip(encoder.inverse_transform(predicted), encoder.inverse_transform(y_test))]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caade77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, clf.predict(X_test), target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd19db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = np.arange(1, 15+1)\n",
    "weights = (\"uniform\", \"distance\")\n",
    "\n",
    "for n in n_neighbors:\n",
    "    for weight in weights:\n",
    "        clf = Pipeline(steps=[\n",
    "          (\"scaler\", StandardScaler()), (\"knn\", KNeighborsClassifier(n_neighbors=n, weights=weight)),\n",
    "        ])\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(\"_\"*82)\n",
    "\n",
    "        print(f\"Classification report for k={n}, weights={weight!r}\")\n",
    "        print(classification_report(y_test, clf.predict(X_test), target_names=encoder.classes_))\n",
    "\n",
    "        print(\"_\"*82)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d463469",
   "metadata": {},
   "source": [
    "# Leaf color identification pipeline (light, medium, dark, dead)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd2f0de",
   "metadata": {},
   "source": [
    "### Using KNN trained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179bb6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get detection box\n",
    "# segment leaf to exclude background (maybe not even needed)\n",
    "# pass class + pixels to data\n",
    "\n",
    "# -> specify size to standardize input (like 50x50, 80x80)\n",
    "# -> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8169b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scg_detection_tools.models import YOLO_NAS, YOLOv8\n",
    "from scg_detection_tools.detect import Detector\n",
    "from scg_detection_tools.utils.file_handling import read_yaml\n",
    "import scg_detection_tools.utils.image_tools as imtools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import cv2\n",
    "\n",
    "cfg = read_yaml(\"analyze_config.yaml\")\n",
    "model = YOLO_NAS(model_arch=cfg[\"yolonas_arch\"], \n",
    "                checkpoint_path=cfg[\"yolonas_model_path\"], \n",
    "                classes=cfg[\"data_classes\"])\n",
    "det_params = cfg[\"detect_parameters\"]\n",
    "det_params[\"embed_slice_callback\"] = None\n",
    "det = Detector(detection_model=model, detection_params=det_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ea8e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scg_detection_tools.utils.image_tools as imtools\n",
    "import scg_detection_tools.utils.cvt as cvt\n",
    "from scg_detection_tools.utils.file_handling import get_all_files_from_paths\n",
    "from scg_detection_tools.dataset import read_dataset_annotation\n",
    "from analyze import parse_seg_annotations\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "IMG_DIR = \"/home/julio/Dev/SCG_IFSC/save/light_group_annotations/images\"\n",
    "LBL_DIR = \"/home/julio/Dev/SCG_IFSC/save/light_group_annotations/labels\"\n",
    "\n",
    "imgs = get_all_files_from_paths(IMG_DIR, skip_ext=[\".txt\", \".json\", \".yaml\"])\n",
    "ann_files, img_ann_idx = parse_seg_annotations(imgs, LBL_DIR)\n",
    "\n",
    "# Keep track of every object as (nclass, obj_crop)\n",
    "obj_data = []\n",
    "\n",
    "# CHOOSING 32x32 because of calculated average\n",
    "STANDARD_SIZE = (32, 32)\n",
    "\n",
    "# !!!!!! taken from data.yaml\n",
    "class_map = {0: \"dark\", 1: \"dead\", 2: \"light\", 3: \"medium\"}\n",
    "\n",
    "for img in imgs:\n",
    "    ann_file = ann_files[img_ann_idx[img]]\n",
    "    annotations = read_dataset_annotation(ann_file, separate_class=False)\n",
    "\n",
    "    # check if contours are boxes or segments\n",
    "    orig = cv2.imread(img)\n",
    "    orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)\n",
    "    imgsz = orig.shape[:2]\n",
    "\n",
    "    for ann in annotations:\n",
    "        nclass = ann[0]\n",
    "        contour = ann[1:]\n",
    "        if len(contour) == 4:\n",
    "            mask = cvt.boxes_to_masks([contour], imgsz=imgsz, normalized=True)[0]\n",
    "        else:\n",
    "            mask = cvt.contours_to_masks([contour], imgsz=imgsz, normalized=True)[0]\n",
    "        \n",
    "        # get only segmented object from image\n",
    "        masked = deepcopy(orig)\n",
    "        masked[mask[:,:] < 255] = 0\n",
    "\n",
    "        # crop a box around it\n",
    "        points = np.array(contour).reshape(len(contour) // 2, 2)\n",
    "        box = cvt.segment_to_box(points, normalized=True, imgsz=imgsz)\n",
    "        obj_crop = imtools.crop_box_image(masked, box)\n",
    "\n",
    "        # resize to 32x32 and add to our data\n",
    "        obj_crop = cv2.resize(obj_crop, STANDARD_SIZE, cv2.INTER_CUBIC)\n",
    "        obj_data.append((nclass, obj_crop))\n",
    "\n",
    "\n",
    "# Get average object size\n",
    "# avg_h = 0\n",
    "# avg_w = 0\n",
    "# for obj in obj_data:\n",
    "#     h, w = obj[1].shape[:2]\n",
    "#     avg_h += h\n",
    "#     avg_w += w\n",
    "# print(f\"Average: W={avg_w / len(obj_data)}, H={avg_h / len(obj_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdc66d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 'obj_data' and split it to have a 'X' vector including the object crops and 'y' being the classes\n",
    "y = []\n",
    "X = []\n",
    "MAX_MEDIUM = 150\n",
    "inc_medium = 0\n",
    "for (nclass, obj_crop) in obj_data:\n",
    "    if nclass == 3:\n",
    "        if inc_medium >= 150:\n",
    "            continue\n",
    "        inc_medium += 1\n",
    "\n",
    "    y.append(nclass)\n",
    "\n",
    "    # For the X vector, we want to include the object as a 32x32x3=3072 length vector\n",
    "    # but we're also including the HSV and Gray cropped object\n",
    "    # so the final array to append to our vector must be of size 32x32x(3 + 3 + 1) = 7168\n",
    "    hsv = cv2.cvtColor(obj_crop, cv2.COLOR_RGB2HSV)\n",
    "    gray = cv2.cvtColor(obj_crop, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    flat_rgb = obj_crop.flatten() # shape 32x32x3 = 3072\n",
    "    flat_hsv = hsv.flatten() # shape 32x32x3 = 3072\n",
    "    flat_gray = gray.flatten() # shape 32x32x1 = 1024\n",
    "\n",
    "    final = np.concatenate((flat_rgb, flat_hsv, flat_gray))\n",
    "    X.append(final)\n",
    "\n",
    "for c in class_map:\n",
    "    print(f\"Samples of class {class_map[c]!r} ({c}): {len([ i for i in y if i == c ])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b95b4406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d0cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we train KNN with our data\n",
    "\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# ELBOW TEST TO CHOOSE N_NEIGHBORS\n",
    "# BEST RESULT SO FAR: K=10\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "for neigh in range(1, 21):\n",
    "    clf = Pipeline(\n",
    "        steps=[ \n",
    "            (\"scaler\", StandardScaler()), \n",
    "            (\"knn\", KNeighborsClassifier(n_neighbors=neigh, weights=\"distance\")),\n",
    "        ]\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Test predictions\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(f\"CONFUSION MATRIX WITH K={neigh}\")\n",
    "    cm = confusion_matrix(y_test, predictions, labels=clf.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[class_map[c] for c in class_map])\n",
    "    print(class_map)\n",
    "    print(classification_report(y_test, predictions, labels=clf.classes_))\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "    # Visualization KNN\n",
    "    # pca = PCA(n_components=2)\n",
    "    # X_test_pca = pca.fit_transform(X_test)\n",
    "\n",
    "    # fig, ax = plt.subplots(figsize=(12,10))\n",
    "    # for cls in np.unique(predictions):\n",
    "    #     ax.scatter(X_test_pca[predictions == cls, 0], \n",
    "    #             X_test_pca[predictions == cls, 1], \n",
    "    #             label=f\"{class_map[cls]}\", \n",
    "    #             s=50, \n",
    "    #             edgecolor='k', \n",
    "    #             alpha=0.8)\n",
    "    # ax.set(xlabel=\"PCA component 1\", ylabel=\"PCA component 2\")\n",
    "    # ax.legend(title=\"Predicted classes\")\n",
    "    # ax.set_title(f\"KNN with k={neigh}\")\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c5b637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train KNN with K=10\n",
    "N_NEIGHBORS = 10\n",
    "clf = Pipeline(\n",
    "    steps=[ \n",
    "        (\"scaler\", StandardScaler()), \n",
    "        (\"knn\", KNeighborsClassifier(n_neighbors=neigh, weights=\"distance\")),\n",
    "    ]\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test predictions\n",
    "predictions = clf.predict(X_test)\n",
    "print(f\"CONFUSION MATRIX WITH K={neigh}\")\n",
    "cm = confusion_matrix(y_test, predictions, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[class_map[c] for c in class_map])\n",
    "print(class_map)\n",
    "print(classification_report(y_test, predictions, labels=clf.classes_))\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398ddd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SVM\n",
    "from sklearn import svm\n",
    "\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# TESTING DIFFERENT SVM KERNELS\n",
    "# BEST SO FAR: 'rbf'\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "for kernel in [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]:\n",
    "    sv_clf = Pipeline(\n",
    "        steps=[\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"svc\", svm.SVC(gamma=\"auto\", kernel=kernel))\n",
    "        ]\n",
    "    )\n",
    "    sv_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Test predictions\n",
    "    predictions = sv_clf.predict(X_test)\n",
    "    print(f\"CONFUSION MATRIX WITH KERNEL={kernel!r}\")\n",
    "    cm = confusion_matrix(y_test, predictions, labels=sv_clf.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[class_map[c] for c in class_map])\n",
    "    print(class_map)\n",
    "    print(classification_report(y_test, predictions, labels=sv_clf.classes_))\n",
    "    disp.plot()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6db18ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with best result kernel: \"rbf\"\n",
    "kernel = \"rbf\"\n",
    "sv_clf = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\", svm.SVC(gamma=\"auto\", kernel=kernel))\n",
    "    ]\n",
    ")\n",
    "sv_clf.fit(X_train, y_train)\n",
    "\n",
    "# Test predictions\n",
    "predictions = sv_clf.predict(X_test)\n",
    "print(f\"CONFUSION MATRIX WITH KERNEL={kernel!r}\")\n",
    "cm = confusion_matrix(y_test, predictions, labels=sv_clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[class_map[c] for c in class_map])\n",
    "print(class_map)\n",
    "print(classification_report(y_test, predictions, labels=sv_clf.classes_))\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0983faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Using KNN trained above to predict on untrained image\n",
    "img = \"/home/julio/Dev/SCG_IFSC/scg-leaf-count/imgs/test/5_640x640_aglom.png\"\n",
    "\n",
    "# -> get image detections\n",
    "# -> crop and segment\n",
    "# -> predict color class\n",
    "# -> display image with color labels\n",
    "\n",
    "detections = det(img)[0]\n",
    "ann_img = imtools.box_annotated_image(img, detections, box_thickness=2)\n",
    "imtools.plot_image(ann_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc02d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scg_detection_tools.segment import SAM2Segment\n",
    "\n",
    "seg = SAM2Segment(sam2_ckpt_path=cfg[\"sam2_ckpt_path\"],\n",
    "                  sam2_cfg=cfg[\"sam2_cfg\"])\n",
    "\n",
    "masks = seg._segment_detection(img, detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a0c7ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scg_detection_tools.utils.cvt as cvt\n",
    "\n",
    "boxes = detections.xyxy.astype(np.int32)\n",
    "orig_img = cv2.imread(img)\n",
    "orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "obj_data = []\n",
    "OBJ_STD_SIZE = (32,32)\n",
    "\n",
    "# Apply mask to segment our image and crop a box around the segmented object\n",
    "for box, mask in zip(boxes, masks):\n",
    "    h, w = mask.shape[1:]\n",
    "    mask = mask.astype(np.uint8).reshape(h, w,)\n",
    "    mask = np.where(mask == 1, 255, 0)\n",
    "\n",
    "    masked = deepcopy(orig_img)\n",
    "    masked[mask[:,:] < 255] = 0\n",
    "\n",
    "    obj_crop = imtools.crop_box_image(masked, box)\n",
    "    obj_crop = cv2.resize(obj_crop, OBJ_STD_SIZE, cv2.INTER_CUBIC)\n",
    "\n",
    "    obj_data.append([box, mask, obj_crop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa07a355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process our object crops to prepare them as input for KNN\n",
    "# -> calculate hsv and gray, then make predictions and append class to our obj data\n",
    "for i, (box, mask, obj) in enumerate(obj_data):\n",
    "    hsv = cv2.cvtColor(obj, cv2.COLOR_RGB2HSV)\n",
    "    gray = cv2.cvtColor(obj, cv2.COLOR_RGB2GRAY)\n",
    "    rgb = obj\n",
    "\n",
    "    attributes = np.concatenate((rgb.flatten(), hsv.flatten(), gray.flatten()))\n",
    "    nclass = clf.predict([attributes])[0]\n",
    "    obj_data[i].append(nclass)\n",
    "\n",
    "print(len(obj_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b545c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "class_color = {\n",
    "    \"light\": \"deepskyblue\",\n",
    "    \"medium\": \"lime\",\n",
    "    \"dark\": \"red\",\n",
    "    \"dead\": \"black\",\n",
    "}\n",
    "\n",
    "color_patches = [\n",
    "    mpatches.Patch(color=class_color[c], label=c) for c in class_color \n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(15,10))\n",
    "axs[0].imshow(orig_img)\n",
    "axs[1].imshow(orig_img)\n",
    "\n",
    "for box, mask, obj_crop, nc in obj_data:\n",
    "\n",
    "    class_name = class_map[nc]\n",
    "    h, w = mask.shape\n",
    "    _mask = np.where(mask == 255, 1, 0).astype(np.uint8).reshape(h, w, 1)\n",
    "    \n",
    "    color = []\n",
    "    color.extend(mcolors.to_rgb(class_color[class_name]))\n",
    "    color.append(0.6)\n",
    "    mask_img = _mask * np.array(color).reshape(1,1,-1)\n",
    "    axs[1].imshow(mask_img)\n",
    "\n",
    "axs[1].legend(handles=color_patches)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478f269d-4b5a-4ee7-a059-1e375344c8df",
   "metadata": {},
   "source": [
    "# Pixel density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c832d-3d6e-4d72-a9c4-9eec91730610",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fa0ce2-ddfd-49c4-81cd-5e3d6cd0d682",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from analyze import analyze_pixel_density\n",
    "from scg_detection_tools.utils.file_handling import get_all_files_from_paths\n",
    "from pathlib import Path\n",
    "\n",
    "IMG_DIR = \"/home/juliocesar/leaf-detection/scg-leaf-count/imgs/analysis\"\n",
    "#LBL_DIR = \"/home/juliocesar/leaf-detection/save/first_analysis_detections/out_cache/\"\n",
    "\n",
    "imgs = get_all_files_from_paths(IMG_DIR)\n",
    "\n",
    "def sort_stem(item):\n",
    "    s = Path(item).stem\n",
    "    try:\n",
    "        val = int(s)\n",
    "        return val\n",
    "    except:\n",
    "        return s\n",
    "\n",
    "imgs = sorted(imgs, key=sort_stem)\n",
    "print(imgs)\n",
    "\n",
    "densities = analyze_pixel_density(model=model, \n",
    "                                  detector=det, \n",
    "                                  imgs=imgs, \n",
    "                                  sam2_ckpt_path=cfg[\"sam2_ckpt_path\"],\n",
    "                                  sam2_cfg=cfg[\"sam2_cfg\"],\n",
    "                                  boxes=False,\n",
    "                                  segments=True,\n",
    "                                  slice_detection=True,\n",
    "                                  on_slice=True,\n",
    "                                  seg_annotations=None,\n",
    "                                  cached_detections=None,\n",
    "                                  show=True,\n",
    "                                  save=False)\n",
    "print(densities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
