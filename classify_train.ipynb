{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification models training\n",
    "\n",
    "Use this notebook to train classification models (KNN, SVM, etc) on leaf color classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pre-annotated dataset with each leaf segmentation and class\n",
    "# From the data.yaml of this dataset, the label number to corresponding class is:\n",
    "# 0=dark, 1=dead, 2=light, 3=medium\n",
    "\n",
    "# This creates a list called 'obj_data', which containg every object as a tuple...\n",
    "# ...containing (obj_classnum, obj_crop)\n",
    "\n",
    "import scg_detection_tools.utils.image_tools as imtools\n",
    "import scg_detection_tools.utils.cvt as cvt\n",
    "from scg_detection_tools.utils.file_handling import get_all_files_from_paths\n",
    "from scg_detection_tools.dataset import read_dataset_annotation\n",
    "from analyze import parse_seg_annotations\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMG_DIR = \"/home/juliocesar/leaf-detection/imgs/light_group/images\"\n",
    "LBL_DIR = \"/home/juliocesar/leaf-detection/imgs/light_group/labels\"\n",
    "\n",
    "#IMG_DIR = \"/home/juliocesar/leaf-detection/imgs/hemacias/annotated/images\"\n",
    "#LBL_DIR = \"/home/juliocesar/leaf-detection/imgs/hemacias/annotated/labels\"\n",
    "\n",
    "imgs = get_all_files_from_paths(IMG_DIR, skip_ext=[\".txt\", \".json\", \".yaml\"])\n",
    "ann_files, img_ann_idx = parse_seg_annotations(imgs, LBL_DIR)\n",
    "\n",
    "# Keep track of every object as (nclass, obj_crop)\n",
    "obj_data = []\n",
    "\n",
    "# CHOOSING 32x32 because of calculated average\n",
    "STANDARD_SIZE = (32, 32)\n",
    "MAX_MEDIUM = 200 # avoid making dataset unbalanced\n",
    "curr_medium = 0\n",
    "\n",
    "# !!!!!! taken from data.yaml\n",
    "class_map = {0: \"dark\", 1: \"dead\", 2: \"light\", 3: \"medium\"}\n",
    "#class_map = {0: \"purple\", 1: \"white\"}\n",
    "\n",
    "for img in imgs:\n",
    "    ann_file = ann_files[img_ann_idx[img]]\n",
    "    annotations = read_dataset_annotation(ann_file, separate_class=False)\n",
    "\n",
    "    # check if contours are boxes or segments\n",
    "    orig = cv2.imread(img)\n",
    "    orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)\n",
    "    imgsz = orig.shape[:2]\n",
    "\n",
    "    for ann in annotations:\n",
    "        nclass = ann[0]\n",
    "        if nclass == 3:\n",
    "            if curr_medium >= MAX_MEDIUM:\n",
    "                continue\n",
    "            else:\n",
    "                curr_medium += 1\n",
    "\n",
    "        contour = ann[1:]\n",
    "        if len(contour) == 4:\n",
    "            mask = cvt.boxes_to_masks([contour], imgsz=imgsz, normalized=True)[0]\n",
    "        else:\n",
    "            mask = cvt.contours_to_masks([contour], imgsz=imgsz, normalized=True)[0]\n",
    "        \n",
    "        # get only segmented object from image\n",
    "        masked = orig.copy()\n",
    "        masked[mask[:,:] < 255] = 0\n",
    "\n",
    "        # crop a box around it\n",
    "        points = np.array(contour).reshape(len(contour) // 2, 2)\n",
    "        box = cvt.segment_to_box(points, normalized=True, imgsz=imgsz)\n",
    "        obj_crop = imtools.crop_box_image(masked, box)\n",
    "\n",
    "        # resize to 32x32 and add to our data\n",
    "        obj_crop = cv2.resize(obj_crop, STANDARD_SIZE, cv2.INTER_CUBIC)\n",
    "        obj_data.append((nclass, obj_crop))\n",
    "\n",
    "\n",
    "ncls = [obj[0] for obj in obj_data]\n",
    "for cls in np.unique(ncls):\n",
    "    print(f\"Samples of type {cls}: {class_map[cls]!r} = {len([c for c in ncls if c == cls])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split between Train and Test to evaluate model as well\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for nclass, obj_crop in obj_data:\n",
    "    X.append(obj_crop)\n",
    "    y.append(nclass)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)\n",
    "class_labels = [class_map[c] for c in class_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing functions (to be able to call clf.predict(imgs) instead of having to extract features first and then calling clf.predict(features))\n",
    "# -> rn_feature_preprocess: use resnet feature extraction to train classificators\n",
    "# -> channels_feature_preprocess: extract RGB, HSV and Gray values from a 32x32 image as features\n",
    "def rn18_feature_preprocess(objX):\n",
    "    import numpy as np\n",
    "\n",
    "    if not isinstance(objX[0], np.ndarray):\n",
    "        raise TypeError(\"'objX' passed to preprocess function must be a list of np.ndarray RGB images\")\n",
    "\n",
    "    from analysis.classify import resnet_extract_features\n",
    "    processed = []\n",
    "    for obj in objX:\n",
    "        processed.append(resnet_extract_features(obj, resnet=18))\n",
    "    return np.array(processed)\n",
    "\n",
    "def rn34_feature_preprocess(objX):\n",
    "    import numpy as np\n",
    "\n",
    "    if not isinstance(objX[0], np.ndarray):\n",
    "        raise TypeError(\"'objX' passed to preprocess function must be a list of np.ndarray RGB images\")\n",
    "\n",
    "    from analysis.classify import resnet_extract_features\n",
    "    processed = []\n",
    "    for obj in objX:\n",
    "        processed.append(resnet_extract_features(obj, resnet=34))\n",
    "    return np.array(processed)\n",
    "\n",
    "def rn50_feature_preprocess(objX):\n",
    "    import numpy as np\n",
    "\n",
    "    if not isinstance(objX[0], np.ndarray):\n",
    "        raise TypeError(\"'objX' passed to preprocess function must be a list of np.ndarray RGB images\")\n",
    "\n",
    "    from analysis.classify import resnet_extract_features\n",
    "    processed = []\n",
    "    for obj in objX:\n",
    "        processed.append(resnet_extract_features(obj, resnet=50))\n",
    "    return np.array(processed)\n",
    "\n",
    "def channels_feature_preprocess(objX):\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "\n",
    "    if not isinstance(objX[0], np.ndarray):\n",
    "        raise TypeError(\"'objX' passed to preprocess function must be a list of np.ndarray RGB images\")\n",
    "\n",
    "    processed = []\n",
    "    for obj in objX:\n",
    "        rgb = cv2.resize(obj, (32,32))\n",
    "        hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "        gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        attributes = np.concatenate((rgb.flatten(), hsv.flatten(), gray.flatten()))\n",
    "        processed.append(attributes)\n",
    "\n",
    "    return np.array(processed)\n",
    "\n",
    "def norm_channels_feature_preprocess(objX):\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    \n",
    "    if not isinstance(objX[0], np.ndarray):\n",
    "        raise TypeError(\"'objX' passed to preprocess function must be a list of np.ndarray RGB images\")\n",
    "\n",
    "    processed = []\n",
    "    for obj in objX:\n",
    "        rgb = cv2.resize(obj, (32,32))\n",
    "        hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "        gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        attributes = np.concatenate((rgb.flatten(), hsv.flatten(), gray.flatten()))\n",
    "        processed.append(attributes)\n",
    "    processed = np.array(processed)\n",
    "    mean = processed.mean(axis=0, keepdims=True)\n",
    "    std = processed.std(axis=0, keepdims=True)\n",
    "    norm = (processed - mean) / (std + 1e-7)\n",
    "\n",
    "    return norm.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters test training (e.g. optimal k value for KNN, loss for SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "############### K VALUE TEST FOR KNN #################\n",
    "######################################################\n",
    "\n",
    "################ CHANNELS FEATURE EXTRACTION\n",
    "### LAST TESTED OPTIMAL K=4 (no nca)\n",
    "\n",
    "from analysis.classify import KNNClassifier\n",
    "\n",
    "MAX_K = 40\n",
    "for k in range(1, MAX_K+1):\n",
    "    knn = KNNClassifier(n_neighbors=k, enable_nca=False, preprocess=channels_feature_preprocess)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"_\"*82)\n",
    "    print(f\"EVALUATION: K = {k}\")\n",
    "    print(\"_\"*82)\n",
    "    knn.evaluate(X_test, y_test, disp_labels=class_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ RESNET18 FEATURE EXTRACTION\n",
    "### LAST TESTED OPTIMAL K=8 AND K=19\n",
    "\n",
    "from analysis.classify import KNNClassifier\n",
    "\n",
    "MAX_K = 40\n",
    "for k in range(1, MAX_K+1):\n",
    "    knn = KNNClassifier(n_neighbors=k, preprocess=rn_feature_preprocess, enable_nca=False)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"_\"*82)\n",
    "    print(f\"EVALUATION: K = {k}\")\n",
    "    print(\"_\"*82)\n",
    "    knn.evaluate(X_test, y_test, disp_labels=class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "################# LOSS TEST FOR SGD ##################\n",
    "######################################################\n",
    "\n",
    "######### CHANNELS FEATURE EXTRACTION\n",
    "# BEST TEST: LOG_LOSS\n",
    "\n",
    "from analysis.classify import SGDBasedClassifier\n",
    "\n",
    "LOSS_FN = [\"hinge\", \"log_loss\", \"modified_huber\", \"squared_hinge\", \"perceptron\", \"squared_error\", \"huber\", \"epsilon_insensitive\", \"squared_epsilon_insensitive\"]\n",
    "for loss in LOSS_FN:\n",
    "    sgd = SGDBasedClassifier(loss=loss, max_iter=1000, preprocess=channels_feature_preprocess)\n",
    "    sgd.fit(X_train, y_train)\n",
    "\n",
    "    print(\"_\"*82)\n",
    "    print(f\"EVALUATION: loss = {loss!r}\")\n",
    "    print(\"_\"*82)\n",
    "    sgd.evaluate(X_test, y_test, disp_labels=class_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### RESNET18 FEATURE EXTRACTION\n",
    "# BEST TEST: HINGE\n",
    "\n",
    "from analysis.classify import SGDBasedClassifier\n",
    "\n",
    "LOSS_FN = [\"hinge\", \"log_loss\", \"modified_huber\", \"squared_hinge\", \"perceptron\", \"squared_error\", \"huber\", \"epsilon_insensitive\", \"squared_epsilon_insensitive\"]\n",
    "for loss in LOSS_FN:\n",
    "    sgd = SGDBasedClassifier(loss=loss, max_iter=1000, preprocess=rn_feature_preprocess)\n",
    "    sgd.fit(X_train, y_train)\n",
    "\n",
    "    print(\"_\"*82)\n",
    "    print(f\"EVALUATION: loss = {loss!r}\")\n",
    "    print(\"_\"*82)\n",
    "    sgd.evaluate(X_test, y_test, disp_labels=class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "##### TRAIN KNN WITH RESNET FEATURE EXTRACTION #####\n",
    "#####################################################\n",
    "\n",
    "from analysis.classify import KNNClassifier\n",
    "\n",
    "# LEAF CLASSIFICATION: K = 8\n",
    "# BLOOD CELL CLASSIFICATION: K = 2\n",
    "\n",
    "resnet_knn = KNNClassifier(n_neighbors=8, preprocess=rn_feature_preprocess)\n",
    "resnet_knn.fit(X_train, y_train)\n",
    "resnet_knn.evaluate(X_test, y_test, disp_labels=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_knn.save_state(\"knn_rn18_k8.skl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "##### TRAIN KNN WITH MANUAL CHANNELS FEATURE EXTRACTION #####\n",
    "#############################################################\n",
    "\n",
    "from analysis.classify import KNNClassifier\n",
    "\n",
    "# LEAF CLASSIFICATION: K = 4\n",
    "# BCELL CLASSIFICATION: K = 5\n",
    "\n",
    "knn = KNNClassifier(n_neighbors=4, preprocess=channels_feature_preprocess)\n",
    "knn.fit(X_train, y_train)\n",
    "knn.evaluate(X_test, y_test, disp_labels=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.save_state(\"knn_k4.skl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "##### TRAIN SVM WITH RESNET FEATURE EXTRACTION #####\n",
    "####################################################\n",
    "\n",
    "from analysis.classify import SVMClassifier\n",
    "\n",
    "sv = SVMClassifier(preprocess=rn_feature_preprocess)\n",
    "sv.fit(X_train, y_train)\n",
    "sv.evaluate(X_test, y_test, disp_labels=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv.save_state(\"svm_rn18.skl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "##### TRAIN SVM WITH MANUAL CHANNEL FEATURE EXTRACTION #####\n",
    "############################################################\n",
    "\n",
    "from analysis.classify import SVMClassifier\n",
    "\n",
    "sv = SVMClassifier(preprocess=channels_feature_preprocess)\n",
    "sv.fit(X_train, y_train)\n",
    "sv.evaluate(X_test, y_test, disp_labels=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv.save_state(\"svm.skl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "##### TRAIN SGD WITH MANUAL CHANNEL FEATURE EXTRACTION #####\n",
    "############################################################\n",
    "\n",
    "from analysis.classify import SGDBasedClassifier\n",
    "\n",
    "sgd = SGDBasedClassifier(loss=\"hinge\", preprocess=channels_feature_preprocess, max_iter=5000)\n",
    "sgd.fit(X_train, y_train)\n",
    "sgd.evaluate(X_test, y_test, disp_labels=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd.save_state(\"sgd.skl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "##### TRAIN SGD WITH RESNET18 FEATURE EXTRACTION #####\n",
    "######################################################\n",
    "\n",
    "from analysis.classify import SGDBasedClassifier\n",
    "\n",
    "sgd = SGDBasedClassifier(loss=\"hinge\", preprocess=rn_feature_preprocess, max_iter=1000)\n",
    "sgd.fit(X_train, y_train)\n",
    "sgd.evaluate(X_test, y_test, disp_labels=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd.save_state(\"sgd_rn18.skl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "##### TRAIN MLP WITH RESNET18 FEATURE EXTRACTION #####\n",
    "######################################################\n",
    "\n",
    "from analysis.classify import MLPClassifier\n",
    "\n",
    "rn_out_features = 512\n",
    "mlp = MLPClassifier(n_features=rn_out_features, n_classes=len(class_map), preprocess=rn_feature_preprocess)\n",
    "\n",
    "mlp.fit(X_train, y_train, epochs=50)\n",
    "mlp.evaluate(X_test, y_test, disp_labels=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.save_state(\"mlp_rn18.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "##### TRAIN MLP WITH CHANNELS FEATURE EXTRACTION #####\n",
    "######################################################\n",
    "\n",
    "from analysis.classify import MLPClassifier\n",
    "\n",
    "n_features = 32*32*(3 + 3 + 1) # 32x32 leaf RGB, HSV and Gray\n",
    "mlp = MLPClassifier(n_features=n_features, n_classes=len(class_map), preprocess=norm_channels_feature_preprocess)\n",
    "\n",
    "mlp.fit(X_train, y_train, epochs=70)\n",
    "mlp.evaluate(X_test, y_test, disp_labels=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.save_state(\"mlp.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking saved states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################\n",
    "## CELLS BELOW ARE FOR CHECKING SAVED MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.classify import KNNClassifier\n",
    "\n",
    "knn = KNNClassifier.from_state(\"/home/juliocesar/leaf-detection/checkpoints/classifiers/knn_k4.skl\")\n",
    "knn.evaluate(X_test, y_test, disp_labels=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.classify import SVMClassifier\n",
    "\n",
    "svm = SVMClassifier.from_state(\"/home/juliocesar/leaf-detection/checkpoints/classifiers/svm.skl\")\n",
    "svm.evaluate(X_test, y_test, disp_labels=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.classify import SGDBasedClassifier\n",
    "\n",
    "sgd = SGDBasedClassifier.from_state(\"/home/juliocesar/leaf-detection/checkpoints/classifiers/sgd.skl\")\n",
    "sgd.evaluate(X_test, y_test, disp_labels=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.classify import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier.from_state(\"mlp.pt\")\n",
    "mlp.evaluate(X_test, y_test, disp_labels=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cls, test_obj = obj_data[9]\n",
    "print(test_cls, test_obj.shape)\n",
    "\n",
    "mlp.eval()\n",
    "print(mlp.predict([test_obj]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leaf-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
