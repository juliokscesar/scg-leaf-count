{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook de Rascunho\n",
    "Qualquer link, recurso, anotação etc. que eu achar importante vou colocando aqui, além de alguns códigos de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links úteis:\n",
    "- [PyTorch](https://pytorch.org/)\n",
    "- [SAHI Framework](https://github.com/obss/sahi/tree/main), [exemplo de uso](https://learnopencv.com/slicing-aided-hyper-inference/).\n",
    "- [Object Detection with Tensorflow](https://www.geeksforgeeks.org/object-detection-using-tensorflow/)\n",
    "- [EfficentDet GitHub](https://github.com/google/automl/tree/master/efficientdet)\n",
    "- [ShapeCN dataset](http://scg.ifsc.usp.br/dataset/ShapeCN.php)\n",
    "- [Supervision Framework Docs](https://supervision.roboflow.com/0.22.0/detection/core/)\n",
    "- [EOLO](https://vlislab22.github.io/EOLO/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando PyTorch e YOLO\n",
    "- [PyTorch Get Started](https://pytorch.org/get-started/locally/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pytorch\n",
    "# CPU (Linux)\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test PyTorch\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "\n",
    "print(\"Is cuda available: \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install some more necessary libraries\n",
    "%pip install numpy opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to install ultralytics package to use YOLO\n",
    "%pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-08-05 15:54:02--  https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving github.com (github.com)... 20.201.28.151\n",
      "Connecting to github.com (github.com)|20.201.28.151|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/661f1788-ea3e-404c-9bd6-57214dbb36fc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240805%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240805T185236Z&X-Amz-Expires=300&X-Amz-Signature=a922e0f1ccb3dc4b2508216d106c199b4962ece7a6c2d73fe916c6d7abbd87d7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8n.pt&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-08-05 15:54:04--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/661f1788-ea3e-404c-9bd6-57214dbb36fc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240805%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240805T185236Z&X-Amz-Expires=300&X-Amz-Signature=a922e0f1ccb3dc4b2508216d106c199b4962ece7a6c2d73fe916c6d7abbd87d7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8n.pt&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6549796 (6,2M) [application/octet-stream]\n",
      "Saving to: ‘models/yolov8n.pt’\n",
      "\n",
      "yolov8n.pt          100%[===================>]   6,25M  1,64MB/s    in 3,7s    \n",
      "\n",
      "2024-08-05 15:54:09 (1,71 MB/s) - ‘models/yolov8n.pt’ saved [6549796/6549796]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download YOLOv8n model\n",
    "!wget -P models/ https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 e:\\Dev\\SCG_IFSC\\scg-plant-detection\\imgs\\onibus.jpeg: 448x640 17 persons, 26 cars, 7 motorcycles, 17 airplanes, 4 buss, 1 truck, 68 boats, 3 fire hydrants, 3 parking meters, 4 benchs, 2 birds, 3 dogs, 5 horses, 1 sheep, 1 bear, 1 zebra, 5 backpacks, 5 umbrellas, 18 handbags, 45 suitcases, 5 frisbees, 6 sports balls, 1 surfboard, 4 bottles, 1 spoon, 1 bowl, 1 banana, 2 couchs, 22 beds, 9 dining tables, 1 laptop, 5 remotes, 5 cell phones, 1 book, 793.2ms\n",
      "Speed: 5.0ms preprocess, 793.2ms inference, 33.0ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "# First, test YOLOv8 with ultralytics api\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"./pretrained_models/yolov8n.pt\")\n",
    "results = model.predict(\"./imgs/onibus.jpeg\", conf=0.6)\n",
    "for result in results:\n",
    "    result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO model\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load YOLOv5\n",
    "#model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5n\")\n",
    "\n",
    "# Load YOLOv8\n",
    "model = torch.hub.load(\"ultralytics/yolov5\", \"custom\", path=\"yolov8n.pt\", source=\"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with Zidane image\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "imgs = [\"https://ultralytics.com/images/zidane.jpg\"]\n",
    "\n",
    "results = model(imgs)\n",
    "results.print()\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando OpenCV (sem nenhum modelo de rede neural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = cv2.imread(\"imgs/cropped/0.png\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blur = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "plt.imshow(blur, cmap=\"gray\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv2.Canny(blur, 10, 150, 3)\n",
    "plt.imshow(canny, cmap=\"gray\")\n",
    "\n",
    "dilated = cv2.dilate(canny, (1, 1), iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cnt, hierarchy) = cv2.findContours(dilated.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "cv2.drawContours(rgb, cnt, -1, (0, 255, 0), 2)\n",
    "plt.imshow(rgb)\n",
    "print(len(cnt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scg-plant-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
